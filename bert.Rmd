---
title: "bert"
author: "Reilly Amera"
date: "2025-04-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(reticulate)
library(readxl)
library(reshape2)
library(lme4)
library(tidyverse)
```

```{r}
# Load the Excel file
df <- read_excel("wordlist.xlsx")

# Remove rows where text is NA or empty
df <- df[!is.na(df$`word only-reilly`) & df$`word only-reilly` != "", ]

# Rename and prep
df <- df[, c("language", "word only-reilly")]
names(df) <- c("language", "text")
df$text <- as.character(df$text)

# Send to Python
py$df <- r_to_py(df)

# Convert to Python
use_virtualenv("r-reticulate", required = TRUE)  # Or use_condaenv()
py$df <- r_to_py(df)

```
 
```{r}
py_run_string("
from transformers import AutoTokenizer, AutoModel
import torch
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity

# Load BERT model
tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-multilingual-uncased')
model = AutoModel.from_pretrained('google-bert/bert-base-multilingual-uncased')

# Generate sentence embedding from CLS token
def get_sentence_embedding(text):
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()

# Embed all texts
def compute_embeddings(df):
    df['embedding'] = df['text'].apply(get_sentence_embedding)
    return df

# Group by language and compute cosine similarity matrices
def cosine_similarity_by_language(df):
    results = {}
    for lang in df['language'].unique():
        subset = df[df['language'] == lang]
        if len(subset) > 1:
            embs = list(subset['embedding'])
            sim_matrix = cosine_similarity(embs)
            results[lang] = sim_matrix
    return results
")

# Run the embedding and similarity pipeline
py$df <- py$compute_embeddings(py$df)
similarities <- py$cosine_similarity_by_language(py$df)

# Example: view matrix for Afrikaans
similarities$afrikaans

```

```{r}
# CSVs per langugae

py_run_string("
import os
import pandas as pd

# Ensure folder exists
os.makedirs('similarity_csvs', exist_ok=True)

# Save each cosine similarity matrix with text labels
for lang in df['language'].unique():
    subset = df[df['language'] == lang].reset_index(drop=True)
    
    if len(subset) > 1:
        texts = list(subset['text'])
        sim_matrix = cosine_similarity([emb for emb in subset['embedding']])
        df_sim = pd.DataFrame(sim_matrix, index=texts, columns=texts)
        
        # Save to CSV
        safe_lang = lang.replace('/', '_')  # In case of problematic characters
        df_sim.to_csv(f'similarity_csvs/cos_{safe_lang}.csv')
")

```

```{r}
en <- read.csv("similarity_csvs/cos_english.csv", row.names = 1)
es <- read.csv("similarity_csvs/cos_spanish.csv")
ko <- read.csv("similarity_csvs/cos_korean.csv", row.names = 1)
ja <- read.csv("similarity_csvs/cos_japanese.csv")
```

```{r}
# Load the wordlist
wordlist <- read_xlsx("wordlist.xlsx")
wordlist <- wordlist[, c("language", "word only", "emotion group")]
colnames(wordlist) <- c("language", "word", "group")

# Get the list of cosine similarity CSVs
file_list <- list.files("similarity_csvs", pattern = "^cos_.*\\.csv$", full.names = TRUE)

# Loop through each similarity matrix
for (file in file_list) {
  tryCatch({
    language <- sub("cos_(.*)\\.csv", "\\1", basename(file))
    message(paste("Processing:", language))

    # Load matrix with first column as 'word', NOT row names
    data <- read.csv(file, check.names = FALSE)
    colnames(data)[1] <- "word"  # Make sure first column is named 'word'

    # Melt into long format
    data_long <- melt(data, id.vars = "word", variable.name = "word2", value.name = "cosine")
    colnames(data_long)[1] <- "word1"

    # Filter wordlist for current language
    roots <- wordlist[wordlist$language == language, c("word", "group")]

    # Merge in group labels for both words
    data_merge <- merge(data_long, roots, by.x = "word1", by.y = "word")
    data_merge <- merge(data_merge, roots, by.x = "word2", by.y = "word")
    colnames(data_merge)[4:5] <- c("group1", "group2")

    # Label comparisons
    data_merge$comparison <- paste(data_merge$group1, "vs", data_merge$group2)
    data_merge$match <- ifelse(
      data_merge$group1 == data_merge$group2, "matched",
      ifelse(
        data_merge$comparison %in% c("sorriness vs gratitude", "gratitude vs sorriness",
                                     "gratitude vs indebtedness", "indebtedness vs gratitude",
                                     "sorriness vs indebtedness", "indebtedness vs sorriness"),
        "unmatched", "random"
      )
    )

    # Remove duplicate pairs (e.g., A+B == B+A)
    data_merge$merged_words <- apply(data_merge[, c("word1", "word2")], 1, function(x) paste(sort(x), collapse = " + "))
    data_merge <- data_merge[!duplicated(data_merge$merged_words), ]

    data_merge$match <- factor(data_merge$match, levels = c("unmatched", "matched", "random"))

    # Define comparisons of interest
    comparisons <- list(
      gratitude_indebtedness = c("gratitude vs gratitude", "indebtedness vs indebtedness", "gratitude vs indebtedness"),
      sorriness_indebtedness = c("sorriness vs sorriness", "indebtedness vs indebtedness", "sorriness vs indebtedness"),
      sorriness_gratitude = c("sorriness vs sorriness", "gratitude vs gratitude", "sorriness vs gratitude")
    )

    for (comp_name in names(comparisons)) {
      comp_data <- data_merge[data_merge$comparison %in% comparisons[[comp_name]], ]

      if (nrow(comp_data) > 0) {
        model <- lmer(cosine ~ match + (1 | group1) + (1 | group2), data = comp_data)
        beta <- fixef(model)["matchmatched"]
        d <- beta / sigma(model)

        # Save model summary
        sink(paste0("model_summary_", language, "_", comp_name, ".txt"))
        cat("Mixed Model Summary:\n")
        print(summary(model))
        cat("\nCohen's d (matched vs unmatched):\n")
        print(d)
        sink()

        # Plot
        p <- ggplot(comp_data, aes(x = match, y = cosine)) +
          geom_violin(fill = "#56B4E9", trim = FALSE) +
          theme_classic() +
          ggtitle(paste("Cosine Similarity:", comp_name, "-", language))
        ggsave(paste0("cosine_similarity_", language, "_", comp_name, ".png"), plot = p)
      }
    }

  }, error = function(e) {
    message(paste("Error in", file, ":", e$message))
  })
}
```

